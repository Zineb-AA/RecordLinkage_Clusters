# -*- coding: utf-8 -*-
"""DC_Blocking.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MgjQgHFqzU0LiwpcQMwC7NqHTFIWITdb
"""

!pip install --upgrade recordlinkage

from google.colab import drive
drive.mount('/content/drive')

! pip install phonetic-fr

import pandas as pd
import recordlinkage as reclin
from phonetic_fr import phonetic
import datetime
#import recordlinkage.preprocessing

## IMPORTING THE DATA FROM A FILE

df_pers = pd.read_excel('/content/drive/MyDrive/File/IA Projects/Data Cleaning/persons_2.xls')

## ADDING PHONETIC ATTRIBUTES

df_pers['firstN_sound'] = df_pers['firstN'].apply(phonetic)
df_pers['lastN_sound'] = df_pers['lastN'].apply(phonetic)

## CHECKING THE DATAFRAME

print ('data shape :',type(df_pers))
print ('data frame colums :',df_pers.columns)
print(len(df_pers['firstN'][8]))
print(len(df_pers['firstN'][9]))
print(df_pers)

################################################ PROCESSING AND COMPARING  RECORDS PAIRS ################################################

## CREATING THE DATAFRAME WHERE TO SAVE THE COMPARISON RESULTS

df_result =pd.DataFrame(columns=['P1_code','P1_firstN','P1_lastN','P2_code','P2_firstN','P2_lastN'])

## CREATING THE PAIR RECORDS USING BLOCKING('ATTRIBUTES')

indexer = reclin.Index()
indexer.block('code')
#indexer.block('firstN')                     #indexer.full() #Make candidate record pairs that agree on one or more variables.
candidate_links = indexer.index(df_pers)     #block('at1'),block('at2') : goup records with the same at1 OR the same at2

## DISPLAY THE  RECORDS PAIRS BEFORE THE COMPARISON (THE BLOCKED RECORD PAIRS)

print(len(candidate_links))
for j in range(len(candidate_links)):
   p1 = candidate_links[j][0]
   p2 = candidate_links[j][1]
   print(" the pair ",j+1 ,"is composed of : ",df_pers['code'][p1],df_pers['firstN'][p1],df_pers['lastN'][p1] ,"&",df_pers['code'][p2],df_pers['firstN'][p2],df_pers['lastN'][p2])

"""############################### THE DIFFERENT DISTANCES ############################################"""

## COMPARING THE PAIRS USING JAROWINKLER

compare_cl = reclin.Compare()
the_method_1 = "jarowinkler"
the_treshold_1 = 0.85
compare_cl.string("firstN", "firstN",method=the_method_1, threshold=the_treshold_1, label="FIRSTNAME")
compare_cl.string("lastN", "lastN",method=the_method_1, threshold=the_treshold_1, label="LASTNAME")
features = compare_cl.compute(candidate_links, df_pers, df_pers)

## COMPARING THE PAIRS USING LEVENSHTEIN

compare_cl = reclin.Compare()
the_method_1 = "levenshtein"
the_treshold_1 = 0.7                                                              #With 0.85 no result, not like jarowinkler
compare_cl.string("firstN", "firstN",method=the_method_1, threshold=the_treshold_1, label="FIRSTNAME")
compare_cl.string("lastN", "lastN",method=the_method_1, threshold=the_treshold_1, label="LASTNAME")
features = compare_cl.compute(candidate_links, df_pers, df_pers)

## COMPARING THE PAIRS USING PHONETIC ATTRIBUTES

compare_cl = reclin.Compare()
the_method_1 = "jarowinkler"
the_treshold_1 = 0.85
compare_cl.string("lastN_sound", "lastN_sound",method=the_method_1, threshold=the_treshold_1, label="FIRSTNAME")
compare_cl.string("firstN_sound", "firstN_sound",method=the_method_1, threshold=the_treshold_1, label="LASTNAME")
features = compare_cl.compute(candidate_links, df_pers, df_pers)

"""############################### DISPLAYING THE RESULTS ############################################"""

## CHECKING THE RESULTS DATAFAME
## features.LASTNAME.index[2][1] Contains the pair record index and features.LASTNAME.values the correspondant probability value

print('features discribe :')
print(features.describe())
print('\nfeatures.LASTNAME.shape')
print(features.LASTNAME.shape)
print('\nfeatures.LASTNAME.ndim')
print(features.LASTNAME.ndim)
print('\nfeatures.LASTNAME.values')
print(features.LASTNAME.values)
print('\nfeatures.LASTNAME.index')
print(features.LASTNAME.index)
print('\nfeatures')
print(features)

## FUNCTION TO DISPLAY THE MAPPED RECORD PAIRS

num_pairs = len(candidate_links)
print ('The total candidate pairs is:', num_pairs, '. The method is:',the_method_1,' using the treshold :',the_treshold_1,'.\n')
print ('The recods pairs with score = 1 are:\n')                                 #for i in features.LASTNAME.values:  print ("The result is :",i) also works
for j in range(num_pairs):
  p1 = features.LASTNAME.index[j][0]
  p2 = features.LASTNAME.index[j][1]
  if features.LASTNAME.values[j] == 1:
    print(features.LASTNAME.values[j],"for the pair : ",df_pers['code'][p1],df_pers['firstN'][p1],df_pers['lastN'][p1] ,"&",df_pers['code'][p2],df_pers['firstN'][p2],df_pers['lastN'][p2])
    df_result = pd.concat([df_result, pd.DataFrame([[df_pers['code'][p1],df_pers['firstN'][p1], df_pers['lastN'][p1], df_pers['code'][p2],df_pers['firstN'][p2], df_pers['lastN'][p2]]], columns=df_result.columns)], ignore_index=True)

## TO OUTPUT THE MATCHED RECORD PAIRS IN A FILE

vdate = format(datetime.datetime.now(),"%Y%m%d%Hh%Mm")
f = open("/content/drive/MyDrive/TGR File/IA Projects/Data Cleaning/Ouputs/pair_"+the_method_1+"_"+vdate+".txt", "a")

for j in range(num_pairs):
  p1 = features.LASTNAME.index[j][0]
  p2 = features.LASTNAME.index[j][1]
  if features.LASTNAME.values[j] == 1:
    print(features.LASTNAME.values[j],"for the pair : ",df_pers['code'][p1],df_pers['firstN'][p1],df_pers['lastN'][p1] ,"&",df_pers['code'][p2],df_pers['firstN'][p2],df_pers['lastN'][p2],file =f)
    df_result = pd.concat([df_result, pd.DataFrame([[df_pers['code'][p1],df_pers['firstN'][p1], df_pers['lastN'][p1], df_pers['code'][p2],df_pers['firstN'][p2], df_pers['lastN'][p2]]], columns=df_result.columns)], ignore_index=True)

f.close()

## OR EXPORTING THE RESULT FROM THE DATAFRAME INTO A FILE

file_path = '/content/drive/MyDrive/TGR File/IA Projects/Data Cleaning/Result_'+the_method_1+vdate+'_.xlsx'
df_result.to_excel(file_path,index=False)

## FUNCTION TO GROUP THE  RECORD PAIRS IN LISTS ( with features.LASTNAME.values[j] == 1)

num_pairs = len(candidate_links)
list_gp = []
for j in range(num_pairs):
  if features.LASTNAME.values[j] == 1 :
    p1 = features.LASTNAME.index[j][0]
    p2 = features.LASTNAME.index[j][1]
    #print ('jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj',j,'ppppppppppppppppp1 and p2 : ',p1,p2)
    if len(list_gp)==0:
      list_gp.append([p1,p2])
    else :
      for i in range(len(list_gp)):
        #print ('loooooooooooooooooooooooooooooooooooooooooooooop',list_gp[i])
        if (p1 in list_gp[i] and p2 in list_gp[i]):
          #print ('in part 0')
          break
        if (p1 in list_gp[i] and p2 not in list_gp[i]):
          #print ('in part 1')
          list_gp[i].append(p2)
          break
        else:
          if (p2 in list_gp[i] and p1 not in list_gp[i]):
            #print ('in part 2')
            list_gp[i].append(p1)
            break
          else:
            if (p1 not in list_gp[i] and p2 not in list_gp[i] and i == len(list_gp) - 1):
                #print ('in part 3')
                list_gp.append([p1,p2])

print ('Final result size :',len(list_gp))
print (list_gp)

## TO OUTPUT THE CLOSE RECORD PAIRS (THE OBTAINED CLUSTERS) IN A FILE

vdate = format(datetime.datetime.now(),"%Y%m%d%Hh%Mm")
f = open("/content/drive/MyDrive/TGR File/IA Projects/Data Cleaning/Ouputs/group_"+the_method_1+"_"+vdate+".txt", "a")

for i in range(len(list_gp)):
  print ('\nTHE RECORDS GROUP #',i+1,': \n',file=f)
  for j in list_gp[i]:
    print (df_pers['code'][j],df_pers['firstN'][j],df_pers['lastN'][j],file=f)

f.close()